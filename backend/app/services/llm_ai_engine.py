"""
LLM-Backed AI Engine Service

Provides LLM-enhanced opportunity matching, roadmap generation, and validation.
Falls back to heuristic methods when LLM is unavailable.
"""

from __future__ import annotations

import os
import json
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field, ValidationError
from sqlalchemy.orm import Session

AI_CALL_TIMEOUT_SECONDS = 30

from app.models.opportunity import Opportunity
from app.models.user import User
from app.models.user_profile import UserProfile
from app.models.expert import Expert
from app.models.success_pattern import SuccessPattern
from app.services.json_codec import loads_json
from app.services.ai_engine import ai_engine_service

logger = logging.getLogger(__name__)


def _extract_json_payload(raw_text: str) -> dict | None:
    if not raw_text:
        return None
    text = raw_text.strip()
    if text.startswith("```"):
        text = text.split("```")[1]
        if text.startswith("json"):
            text = text[4:]
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return None


def _extract_anthropic_usage(response: Any) -> dict | None:
    usage = getattr(response, "usage", None)
    if not usage:
        return None
    input_tokens = getattr(usage, "input_tokens", None)
    output_tokens = getattr(usage, "output_tokens", None)
    total_tokens = None
    if isinstance(input_tokens, int) and isinstance(output_tokens, int):
        total_tokens = input_tokens + output_tokens
    return {
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": total_tokens,
    }


def _capture_ai_exception(error: Exception, *, stage: str, model: str, extra: Optional[dict] = None) -> None:
    try:
        import sentry_sdk
        with sentry_sdk.push_scope() as scope:
            scope.set_tag("ai_stage", stage)
            scope.set_tag("ai_model", model)
            if extra:
                scope.set_extra("context", extra)
            sentry_sdk.capture_exception(error)
    except Exception:
        return


def _capture_ai_warning(message: str, *, stage: str, model: str, extra: Optional[dict] = None) -> None:
    try:
        import sentry_sdk
        with sentry_sdk.push_scope() as scope:
            scope.set_tag("ai_stage", stage)
            scope.set_tag("ai_model", model)
            if extra:
                scope.set_extra("context", extra)
            sentry_sdk.capture_message(message, level="warning")
    except Exception:
        return


class _MatchLLMResult(BaseModel):
    fit_score: int = Field(..., ge=0, le=100)
    confidence: float = Field(..., ge=0)
    gaps: List[str] = Field(default_factory=list)
    insights: List[str] = Field(default_factory=list)
    recommended_actions: List[str] = Field(default_factory=list)


class _RoadmapLLMResult(BaseModel):
    timeline_weeks: int = Field(..., ge=1)
    milestones: List[dict] = Field(default_factory=list)
    success_probability: Optional[int] = Field(default=None, ge=0, le=100)
    capital_estimate_cents: Optional[int] = Field(default=None, ge=0)
    key_assumptions: List[str] = Field(default_factory=list)


class _ValidationLLMResult(BaseModel):
    validation_score: int = Field(..., ge=0, le=100)
    verdict: str
    market_analysis: Optional[str] = None
    competitive_landscape: Optional[str] = None
    key_risks: List[str] = Field(default_factory=list)
    next_steps: List[str] = Field(default_factory=list)
    success_factors: Optional[str] = None
    pivot_suggestions: Optional[str] = None


def get_anthropic_client():
    """Get Anthropic client with credentials from Replit AI Integrations or environment."""
    api_key = os.getenv("AI_INTEGRATIONS_ANTHROPIC_API_KEY")
    base_url = os.getenv("AI_INTEGRATIONS_ANTHROPIC_BASE_URL")
    
    if api_key and base_url:
        try:
            import anthropic
            logger.info("Using Replit AI Integrations for Anthropic")
            return anthropic.Anthropic(api_key=api_key, base_url=base_url)
        except Exception as e:
            logger.error(f"Failed to create Anthropic client with AI Integrations: {e}")
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        api_key = os.getenv("CLAUDE_API_KEY")
    if not api_key:
        api_key = os.getenv("CLAUDE_API")
    
    if not api_key:
        logger.warning("No Anthropic API key found")
        return None
    
    try:
        import anthropic
        return anthropic.Anthropic(api_key=api_key)
    except Exception as e:
        logger.error(f"Failed to create Anthropic client: {e}")
        return None


class LLMAIEngineService:
    """
    LLM-enhanced AI Engine service.
    
    Uses Claude for:
    - Smarter opportunity-user matching with personalized insights
    - Detailed roadmap generation with customized milestones
    - Comprehensive validation with market analysis
    - Learning from success_patterns for better predictions
    """
    
    def __init__(self):
        self.model = "claude-sonnet-4-5"
        self.fast_model = "claude-haiku-4-5"
    
    def _get_success_patterns_context(self, db: Session, opportunity_type: str = None, limit: int = 5) -> str:
        """Get relevant success patterns for context."""
        q = db.query(SuccessPattern)
        if opportunity_type:
            q = q.filter(SuccessPattern.opportunity_type == opportunity_type)
        patterns = q.order_by(SuccessPattern.created_at.desc()).limit(limit).all()
        
        if not patterns:
            return "No historical success patterns available yet."
        
        context_parts = []
        for p in patterns:
            experts = loads_json(p.experts_used, default=[])
            factors = loads_json(p.success_factors, default=[])
            context_parts.append(
                f"- Revenue: ${float(p.revenue_generated or 0):,.0f}, "
                f"Capital: ${float(p.capital_spent or 0):,.0f}, "
                f"Experts: {len(experts)}, "
                f"Key factors: {', '.join(factors[:3]) if factors else 'N/A'}"
            )
        
        return "Historical success patterns:\n" + "\n".join(context_parts)
    
    def match_opportunity_to_user_llm(
        self, 
        db: Session, 
        user: User, 
        opportunity_id: int,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        LLM-enhanced opportunity matching.
        
        Provides personalized fit analysis and recommendations.
        """
        opp = db.query(Opportunity).filter(Opportunity.id == opportunity_id).first()
        if not opp:
            raise ValueError("Opportunity not found")
        
        profile = db.query(UserProfile).filter(UserProfile.user_id == user.id).first()
        
        heuristic_result = ai_engine_service.match_opportunity_to_user(db, user, opportunity_id)
        
        if not use_llm:
            return heuristic_result
        
        client = get_anthropic_client()
        if not client:
            logger.info("LLM not available, using heuristic match")
            return heuristic_result
        
        try:
            user_skills = loads_json(profile.skills if profile else None, default=[])
            user_capital = profile.available_capital if profile else None
            user_time = profile.time_commitment_hours_per_week if profile else None
            
            success_context = self._get_success_patterns_context(db, opp.category)
            
            prompt = f"""Analyze the fit between this user and opportunity.

OPPORTUNITY:
- Title: {opp.title}
- Category: {opp.category}
- Description: {opp.description[:500] if opp.description else 'N/A'}
- Validation Count: {opp.validation_count or 0}
- AI Score: {opp.ai_opportunity_score or 'Not scored'}

USER PROFILE:
- Skills: {', '.join(user_skills[:10]) if user_skills else 'Not specified'}
- Available Capital: ${float(user_capital):,.0f} if {user_capital} else 'Not specified'
- Weekly Time Commitment: {user_time} hours if {user_time} else 'Not specified'

{success_context}

Provide a JSON response with:
1. "fit_score": 0-100 score of how well this opportunity fits the user
2. "confidence": 0-1 confidence in the assessment
3. "gaps": array of skill/resource gaps the user has
4. "insights": 2-3 personalized insights about this match
5. "recommended_actions": 2-3 specific next steps

Respond only with valid JSON."""

            response = client.messages.create(
                model=self.fast_model,
                max_tokens=800,
                messages=[{"role": "user", "content": prompt}]
            )
            usage = _extract_anthropic_usage(response)
            
            payload = _extract_json_payload(response.content[0].text)
            if payload is None:
                raise ValueError("Invalid JSON payload from LLM")

            parsed = _MatchLLMResult.model_validate(payload)
            confidence = parsed.confidence
            if confidence <= 1:
                confidence = confidence * 100
            confidence = max(0, min(100, int(round(confidence))))

            return {
                "fit_score": parsed.fit_score,
                "confidence": confidence,
                "gaps": parsed.gaps or heuristic_result["gaps"],
                "insights": parsed.insights,
                "recommended_actions": parsed.recommended_actions,
                "recommended_experts": heuristic_result["recommended_experts"],
                "llm_enhanced": True,
                "ai_provider": "claude",
                "ai_usage": usage,
            }
            
        except (ValueError, ValidationError, json.JSONDecodeError) as e:
            _capture_ai_warning(
                "LLM match schema invalid",
                stage="match",
                model=self.fast_model,
                extra={"opportunity_id": opportunity_id, "error": str(e)},
            )
            logger.warning(f"LLM match schema invalid, using heuristic: {e}")
            return heuristic_result
        except Exception as e:
            _capture_ai_exception(
                e,
                stage="match",
                model=self.fast_model,
                extra={"opportunity_id": opportunity_id},
            )
            logger.error(f"LLM match failed, using heuristic: {e}")
            return heuristic_result
    
    def generate_roadmap_llm(
        self,
        db: Session,
        user: User,
        opportunity_id: int,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        LLM-enhanced roadmap generation.
        
        Creates personalized milestones based on user profile and success patterns.
        """
        opp = db.query(Opportunity).filter(Opportunity.id == opportunity_id).first()
        if not opp:
            raise ValueError("Opportunity not found")
        
        heuristic_result = ai_engine_service.generate_roadmap(db, user, opportunity_id)
        
        if not use_llm:
            return heuristic_result
        
        client = get_anthropic_client()
        if not client:
            logger.info("LLM not available, using heuristic roadmap")
            return heuristic_result
        
        try:
            profile = db.query(UserProfile).filter(UserProfile.user_id == user.id).first()
            user_skills = loads_json(profile.skills if profile else None, default=[])
            user_time = profile.time_commitment_hours_per_week if profile else 10
            
            success_context = self._get_success_patterns_context(db, opp.category)
            
            prompt = f"""Generate a personalized execution roadmap for this opportunity.

OPPORTUNITY:
- Title: {opp.title}
- Category: {opp.category}
- Description: {opp.description[:500] if opp.description else 'N/A'}
- AI Next Steps: {loads_json(opp.ai_next_steps, default=['Validate problem', 'Build MVP', 'Launch'])}

USER CONTEXT:
- Skills: {', '.join(user_skills[:8]) if user_skills else 'General'}
- Weekly hours available: {user_time}

{success_context}

Create a JSON response with:
1. "timeline_weeks": estimated total weeks to MVP
2. "milestones": array of 5-8 milestones, each with:
   - "week": target week number
   - "title": milestone title
   - "description": what to accomplish
   - "deliverables": specific deliverables
   - "estimated_hours": hours needed
3. "success_probability": 0-100 probability estimate
4. "capital_estimate_cents": estimated capital needed in cents
5. "key_assumptions": list of assumptions

Respond only with valid JSON."""

            response = client.messages.create(
                model=self.fast_model,
                max_tokens=1200,
                messages=[{"role": "user", "content": prompt}]
            )
            usage = _extract_anthropic_usage(response)
            
            payload = _extract_json_payload(response.content[0].text)
            if payload is None:
                raise ValueError("Invalid JSON payload from LLM")

            parsed = _RoadmapLLMResult.model_validate(payload)

            return {
                "opportunity_id": opportunity_id,
                "timeline_weeks": parsed.timeline_weeks,
                "milestones": parsed.milestones or heuristic_result["milestones"],
                "success_probability": parsed.success_probability,
                "capital_estimate_cents": parsed.capital_estimate_cents,
                "key_assumptions": parsed.key_assumptions,
                "risks": heuristic_result.get("risks", []),
                "llm_enhanced": True,
                "ai_provider": "claude",
                "ai_usage": usage,
            }
            
        except (ValueError, ValidationError, json.JSONDecodeError) as e:
            _capture_ai_warning(
                "LLM roadmap schema invalid",
                stage="roadmap",
                model=self.fast_model,
                extra={"opportunity_id": opportunity_id, "error": str(e)},
            )
            logger.warning(f"LLM roadmap schema invalid, using heuristic: {e}")
            return heuristic_result
        except Exception as e:
            _capture_ai_exception(
                e,
                stage="roadmap",
                model=self.fast_model,
                extra={"opportunity_id": opportunity_id},
            )
            logger.error(f"LLM roadmap failed, using heuristic: {e}")
            return heuristic_result
    
    def validate_opportunity_llm(
        self,
        db: Session,
        user: User,
        opportunity_id: int,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        LLM-enhanced opportunity validation.
        
        Provides comprehensive market and feasibility analysis.
        """
        opp = db.query(Opportunity).filter(Opportunity.id == opportunity_id).first()
        if not opp:
            raise ValueError("Opportunity not found")
        
        heuristic_result = ai_engine_service.validate_opportunity(db, user, opportunity_id)
        
        if not use_llm:
            return heuristic_result
        
        client = get_anthropic_client()
        if not client:
            logger.info("LLM not available, using heuristic validation")
            return heuristic_result
        
        try:
            success_context = self._get_success_patterns_context(db, opp.category)
            
            prompt = f"""Validate this business opportunity and provide actionable analysis.

OPPORTUNITY:
- Title: {opp.title}
- Category: {opp.category}
- Description: {opp.description[:800] if opp.description else 'N/A'}
- Validation Count: {opp.validation_count or 0}
- Current AI Score: {opp.ai_opportunity_score or 'Not scored'}
- Severity: {opp.severity or 3}/5

{success_context}

Provide a comprehensive JSON response with:
1. "validation_score": 0-100 overall score
2. "verdict": "fast_track" (80+), "refine" (60-79), or "pivot" (<60)
3. "market_analysis": brief market opportunity assessment
4. "competitive_landscape": brief competitive analysis
5. "key_risks": array of top 3-5 risks
6. "next_steps": array of 3-5 actionable next steps
7. "success_factors": what would make this succeed
8. "pivot_suggestions": alternative directions if score is low

Respond only with valid JSON."""

            response = client.messages.create(
                model=self.model,
                max_tokens=1500,
                messages=[{"role": "user", "content": prompt}]
            )
            usage = _extract_anthropic_usage(response)
            
            payload = _extract_json_payload(response.content[0].text)
            if payload is None:
                raise ValueError("Invalid JSON payload from LLM")

            parsed = _ValidationLLMResult.model_validate(payload)

            return {
                "opportunity_id": opportunity_id,
                "validation_score": parsed.validation_score,
                "verdict": parsed.verdict or heuristic_result["verdict"],
                "market_analysis": parsed.market_analysis,
                "competitive_landscape": parsed.competitive_landscape,
                "key_risks": parsed.key_risks or heuristic_result["key_risks"],
                "next_steps": parsed.next_steps or heuristic_result["next_steps"],
                "success_factors": parsed.success_factors,
                "pivot_suggestions": parsed.pivot_suggestions,
                "llm_enhanced": True,
                "ai_provider": "claude",
                "ai_usage": usage,
            }
            
        except (ValueError, ValidationError, json.JSONDecodeError) as e:
            _capture_ai_warning(
                "LLM validation schema invalid",
                stage="validate",
                model=self.model,
                extra={"opportunity_id": opportunity_id, "error": str(e)},
            )
            logger.warning(f"LLM validation schema invalid, using heuristic: {e}")
            return heuristic_result
        except Exception as e:
            _capture_ai_exception(
                e,
                stage="validate",
                model=self.model,
                extra={"opportunity_id": opportunity_id},
            )
            logger.error(f"LLM validation failed, using heuristic: {e}")
            return heuristic_result


    async def generate_response(self, prompt: str, model: str = "deepseek") -> Dict[str, Any]:
        """
        Generate a response from the AI model.
        
        Args:
            prompt: The prompt to send to the model
            model: Which model to use ("deepseek" or "claude")
        
        Returns:
            Dictionary with the response
        """
        client = get_anthropic_client()
        if not client:
            logger.warning("No AI client available, returning empty response")
            return {"error": "ai_unavailable", "error_message": "AI service not available", "response": None}
        
        try:
            model_id = self.fast_model if model == "deepseek" else self.model
            
            def sync_call():
                return client.messages.create(
                    model=model_id,
                    max_tokens=1500,
                    messages=[{"role": "user", "content": prompt}]
                )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(sync_call),
                timeout=AI_CALL_TIMEOUT_SECONDS
            )
            
            response_text = response.content[0].text.strip()
            usage = _extract_anthropic_usage(response)

            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]

            try:
                parsed = json.loads(response_text)
                return {"response": parsed, "raw": response_text, "usage": usage, "tokens_used": (usage or {}).get("total_tokens")}
            except json.JSONDecodeError:
                return {"response": response_text, "raw": response_text, "usage": usage, "tokens_used": (usage or {}).get("total_tokens")}
        
        except asyncio.TimeoutError as exc:
            logger.error(f"AI generation timed out after {AI_CALL_TIMEOUT_SECONDS}s")
            _capture_ai_exception(exc, stage="generate_response", model=model, extra={"prompt_chars": len(prompt)})
            return {"error": "ai_timeout", "error_message": f"AI call timed out after {AI_CALL_TIMEOUT_SECONDS} seconds", "response": None}
        except Exception as e:
            _capture_ai_exception(e, stage="generate_response", model=model, extra={"prompt_chars": len(prompt)})
            logger.error(f"AI generation failed: {e}")
            return {"error": "ai_error", "error_message": str(e), "response": None}


llm_ai_engine_service = LLMAIEngineService()
